{{ template "chart.header" . }}

{{/* {{ template "chart.badgesSection" . }} */}}

{{ template "chart.typeBadge" . }} {{ template "chart.appVersionBadge" . }}

{{ template "chart.description" . }}

A Helm chart to deploy a free and completely Open Source chatbot web service with UI and API on CPU or GPU.

Visit the Libre Chat documentation website for more details on how to configure it: [vemonet.github.io/libre-chat](https://vemonet.github.io/libre-chat)

We recommend to use a `values.yml` file that you pass to `helm install` to configure the chatbot. Start from the default `values.yaml` file in this repository.


## Installing the Chart

Install the DSRI Helm Charts on your machine, if not already done:

```bash
helm repo add dsri https://maastrichtu-ids.github.io/dsri-helm-charts/
helm repo update
```

## Deploying the Chart

### On CPU

To deploy the chart **on CPU** with the release name `{{ template "chart.name" . }}` using a `values.yml` file:

```bash
helm install {{ template "chart.name" . }} dsri/{{ template "chart.name" . }} -f values.yml
```

<!--
### On GPU

You can also use this chart to deploy JupyterLab **on GPU**, here is an example with the release name `{{ template "chart.name" . }}-gpu`, using the existing `anyuid` service account, and our custom [`ghcr.io/vemonet/libre-chat:gpu` image:

```bash
helm install {{ template "chart.name" . }}-gpu dsri/{{ template "chart.name" . }} \
  -f values.yml \
  --set service.openshiftRoute.enabled=true \
  --set image.repository=ghcr.io/vemonet/libre-chat \
  --set image.tag=gpu \
  --set image.pullPolicy=Always \
  --set resources.requests."nvidia\.com/gpu"=1 \
  --set resources.limits."nvidia\.com/gpu"=1 \
  --set tolerations[0].effect=NoSchedule \
  --set tolerations[0].key=nvidia.com/gpu \
  --set tolerations[0].operator=Exists \
  --set password=changeme
```
-->

You can add an additional existing volume easily:

```bash
  --set storage.extraStorage[0].name=scratch-storage \
  --set storage.extraStorage[0].mountPath=/workspace/scratch \
  --set storage.extraStorage[0].readOnly=false \
```

If you deployed your application with an OpenShift Route, you can retrieve the URL of the deloyed application with this command, after changing `{{ template "chart.name" . }}` by your application name:

```bash
oc get route --selector app.kubernetes.io/instance={{ template "chart.name" . }} --no-headers -o=custom-columns=HOST:.spec.host
```

## Checking the logs

Get the events related to your chart deployment (replace `oc` by `kubectl` for Kubernetes):

```bash
oc get events | grep {{ template "chart.name" . }}
```

Get logs of the chart deployment:

```bash
oc logs deployment/{{ template "chart.name" . }} --tail 100
```

## Updating the image in a deployed chart

To be able to trigger an update of the image deployed by the chart you will need to set `image.pullPolicy=Always` when deploying the chart.

You can then update the image used by the running JupyterLab:

```bash
helm upgrade {{ template "chart.name" . }} dsri/{{ template "chart.name" . }}
```

## Uninstalling the Chart

To uninstall/delete the `{{ template "chart.name" . }}` deployment:

```bash
helm delete {{ template "chart.name" . }}
```

The command removes all the Kubernetes components associated with the chart and deletes the release.


## Configuration

The following table lists the configurable parameters of the {{ template "chart.name" . }} chart and their default values. They can be defined in the `values.yaml` file, or using the flag `--set`.

{{ template "chart.valuesTable" . }}